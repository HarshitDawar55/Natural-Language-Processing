{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c285c72",
   "metadata": {},
   "source": [
    "# Topic Modelling by `Mr. Harshit Dawar!`\n",
    "### Algorithm: LDA (Latent Dirichlet Allocation)\n",
    "\n",
    "***Steps***\n",
    "1. A random number of topics will be decided by the user to which the words from the document will be assigned.\n",
    "2. Each word from each document will be assigned to any of the random topics initially.\n",
    "3. Now, random topics from each document & words assignments to those topics in each document will be obtained. Although, initial assignment will not make any sense.\n",
    "4. Steps 2 & 3 will be repeated until the best assignments are provided using the formula given below.\n",
    "\n",
    "For each topic:  ***probability( topic \"t\" | document \"d\")*** <= Probability of topic \"t\" existing in document \"d\".\n",
    "\n",
    "For each word:  ***probability( word \"w\" | topic \"t\")*** <= Probability of word \"w\" belonging to topic \"t\".\n",
    "\n",
    "Final probability that a topic \"t\" generated word \"w\" in document \"d\": ***probability( topic \"t\" | document \"d\") * probability( word \"w\" | topic \"t\")***\n",
    "\n",
    "\n",
    "**Important Pointers**\n",
    "\n",
    "* The user has to decide the number of topics to get from the document\n",
    "* The user has to interpret the topics itself.\n",
    "\n",
    "**Few Assumptions of LDA**\n",
    "\n",
    "* Documents are probability distributions over Topics, Topics are probabilty distributions over words.\n",
    "* Documents with similar topics uses similar groups of words.\n",
    "* Topics can be founded by searching for the words that occur across the corpus in documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0887e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7507a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dataset\n",
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c54fa29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article\n",
       "0  In the Washington of 2016, even when the polic...\n",
       "1    Donald Trump has used Twitter  —   his prefe...\n",
       "2    Donald Trump is unabashedly praising Russian...\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4  From photography, illustration and video, to d..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff4aa038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11992, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506c51c",
   "metadata": {},
   "source": [
    "## Getting the word vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c96d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* min_df represents min. number of documents in which a word should occur. A word with a number below this\n",
    "  will be ignored.\n",
    "* max_df represents max. word frequency of occurence of a word in the document above which all the\n",
    "  words will be ignored.\n",
    "  \n",
    "* Stopwrods of English will be removed.\n",
    "\"\"\"\n",
    "vectorizer = CountVectorizer(min_df = 2, max_df = 0.95, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b1ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_word_matrix = vectorizer.fit_transform(data.Article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7e7bc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15a2b716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 15, 19])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(document_word_matrix.toarray()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed76f79",
   "metadata": {},
   "source": [
    "## Applying LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e161b3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=9, random_state=5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "n_components: number of different topics to divide the documents into\n",
    "\"\"\"\n",
    "LDA = LatentDirichletAllocation(n_components = 9, random_state = 5)\n",
    "\n",
    "LDA.fit(document_word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62b646c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54777"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Getting the Corpus from the Documents\n",
    "\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b39296d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bask', 'benzodiazepines', 'nas')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[5000], vectorizer.get_feature_names()[5500], vectorizer.get_feature_names()[33000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a5091dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.04108203e+01, 4.93163268e+02, 1.11111111e-01, ...,\n",
       "        6.11103023e+00, 1.11675663e-01, 1.11111111e-01],\n",
       "       [2.92231210e+00, 7.68997627e+02, 1.11111111e-01, ...,\n",
       "        1.11111111e-01, 1.11119937e-01, 1.11113664e-01],\n",
       "       [1.11189038e-01, 1.75726089e+02, 1.11113075e-01, ...,\n",
       "        1.11119789e-01, 1.11036644e+00, 1.11111111e-01],\n",
       "       ...,\n",
       "       [7.29581971e+00, 1.67203972e+03, 1.11111111e-01, ...,\n",
       "        1.11138772e-01, 1.11288688e-01, 1.11111111e-01],\n",
       "       [7.94521735e+00, 4.38966163e+01, 1.11111111e-01, ...,\n",
       "        1.11111111e-01, 1.11111111e-01, 1.11111648e-01],\n",
       "       [4.56026646e+00, 3.66501790e+02, 1.11116300e-01, ...,\n",
       "        1.11111669e-01, 1.11111111e-01, 1.11111966e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Getting the Different Topics\n",
    "LDA.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8837eed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 54777)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b672cb6",
   "metadata": {},
   "source": [
    "### Getting Word to Topic Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae08746c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.04108203e+01, 4.93163268e+02, 1.11111111e-01, ...,\n",
       "       6.11103023e+00, 1.11675663e-01, 1.11111111e-01])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Topic_1 = LDA.components_[0]\n",
    "Topic_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0f3c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the top 15 words from this topic\n",
    "top_15_words_of_topic_1 = Topic_1.argsort()[-15 : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bd590a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work\n",
      "way\n",
      "home\n",
      "day\n",
      "new\n",
      "life\n",
      "world\n",
      "women\n",
      "family\n",
      "time\n",
      "years\n",
      "just\n",
      "people\n",
      "like\n",
      "says\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "index will be the word index & actual words are present in the vocabulary/corpus\n",
    "not in the Topic1, it contains just the probabilities for the words.\n",
    "\"\"\" \n",
    "for index in top_15_words_of_topic_1:\n",
    "    print(vectorizer.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd56bc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 words for Topic: 1\n",
      "['work', 'way', 'home', 'day', 'new', 'life', 'world', 'women', 'family', 'time', 'years', 'just', 'people', 'like', 'says']\n",
      "**************************************************\n",
      "\n",
      "Top 15 words for Topic: 2\n",
      "['just', 'going', 'state', 'political', 'obama', 'donald', 'country', 'says', 'new', 'campaign', 'people', 'clinton', 'president', 'said', 'trump']\n",
      "**************************************************\n",
      "\n",
      "Top 15 words for Topic: 3\n",
      "['democrats', 'won', 'new', 'party', 'states', 'democratic', 'win', 'race', 'said', 'vote', 'percent', 'clinton', 'voters', 'sanders', 'state']\n",
      "**************************************************\n",
      "\n",
      "Top 15 words for Topic: 4\n",
      "['years', 'life', 've', 'don', 'says', 'music', 'way', 'really', 'new', 'know', 'time', 'think', 'people', 'just', 'like']\n",
      "**************************************************\n",
      "\n",
      "Top 15 words for Topic: 5\n",
      "['hospital', 'don', 'disease', 'just', 'women', 'drug', 'like', 'police', 'medical', 'care', 'patients', 'said', 'health', 'people', 'says']\n",
      "**************************************************\n",
      "\n",
      "Top 15 words for Topic: 6\n",
      "['npr', 'killed', 'military', 'attack', 'according', 'told', 'country', 'war', 'city', 'reports', 'government', 'police', 'people', 'says', 'said']\n",
      "**************************************************\n",
      "\n",
      "Top 15 words for Topic: 7\n",
      "['year', 'water', 'years', 'university', 'study', 'just', 'food', 'school', 'new', 'students', 'health', 'percent', 'like', 'people', 'says']\n",
      "**************************************************\n",
      "\n",
      "Top 15 words for Topic: 8\n",
      "['republicans', 'congress', 'comey', 'intelligence', 'russian', 'administration', 'committee', 'senate', 'white', 'russia', 'obama', 'house', 'said', 'president', 'trump']\n",
      "**************************************************\n",
      "\n",
      "Top 15 words for Topic: 9\n",
      "['government', 'order', 'department', 'judge', 'new', 'news', 'company', 'justice', 'state', 'federal', 'case', 'says', 'law', 'said', 'court']\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, topic in enumerate(LDA.components_):\n",
    "    print(\"Top 15 words for Topic:\", index + 1)\n",
    "    print(list(vectorizer.get_feature_names()[word_index] for word_index in topic.argsort()[-15 : ]))\n",
    "    print(\"*\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74786df4",
   "metadata": {},
   "source": [
    "### Getting Topic to Document Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "024310d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_attachments_to_documents = LDA.transform(document_word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5a01ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.74816323e-04, 1.40156284e-01, 1.74819014e-04, ...,\n",
       "        1.74830177e-04, 8.11023247e-01, 7.23389538e-03],\n",
       "       [3.42081374e-04, 2.76590295e-01, 3.42049311e-04, ...,\n",
       "        3.42013870e-04, 5.63406622e-01, 3.42058426e-04],\n",
       "       [2.54964364e-04, 1.13054360e-01, 2.55019594e-04, ...,\n",
       "        2.54921261e-04, 8.70353776e-01, 2.54962856e-04],\n",
       "       ...,\n",
       "       [4.46646671e-01, 3.08857580e-04, 3.25828615e-02, ...,\n",
       "        2.40554503e-02, 3.08840917e-04, 3.08926005e-04],\n",
       "       [3.35943737e-04, 3.88437787e-01, 3.27103262e-01, ...,\n",
       "        3.35844133e-04, 2.29261164e-01, 3.35892474e-04],\n",
       "       [1.61390923e-01, 2.56396867e-01, 6.35280896e-02, ...,\n",
       "        5.62936234e-02, 1.97113047e-04, 1.97120171e-04]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contains probabilities for each document to belong to a particular topic!\n",
    "topic_attachments_to_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00336e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11992, 9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_attachments_to_documents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf7b1d",
   "metadata": {},
   "source": [
    "### Assigning Labels to the Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18669f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column for the topics for each document in the dataset!\n",
    "data[\"Topic\"] = topic_attachments_to_documents.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19bd08bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Increasing the topic by number as I am taking topic numbering from 1, not from 0.\n",
    "This will help to compare the words present in the topic that are displayed above!\n",
    "\"\"\"\n",
    "data.Topic = data.Topic.apply(lambda x: x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85c2a807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  Topic\n",
       "0  In the Washington of 2016, even when the polic...      8\n",
       "1    Donald Trump has used Twitter  —   his prefe...      8\n",
       "2    Donald Trump is unabashedly praising Russian...      8\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...      8\n",
       "4  From photography, illustration and video, to d...      7"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "65e4218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Giving Topic Labels\n",
    "topic_labels = {1 : \"Family\",\n",
    "                2 : \"politics\",\n",
    "                3 : \"State Politics\",\n",
    "                4 : \"Music\",\n",
    "                5 : \"Pharmacy/Drugs\",\n",
    "                6 : \"War\",\n",
    "                7 : \"Education\",\n",
    "                8 : \"Presidential Management\",\n",
    "                9 : \"Justice & Court\"}\n",
    "\n",
    "data[\"Topic Labels\"] = data.Topic.map(topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "852b9176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Topic Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>8</td>\n",
       "      <td>Presidential Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>8</td>\n",
       "      <td>Presidential Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>8</td>\n",
       "      <td>Presidential Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>8</td>\n",
       "      <td>Presidential Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>7</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I did not want to join yoga class. I hated tho...</td>\n",
       "      <td>5</td>\n",
       "      <td>Pharmacy/Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>With a   who has publicly supported the debunk...</td>\n",
       "      <td>5</td>\n",
       "      <td>Pharmacy/Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I was standing by the airport exit, debating w...</td>\n",
       "      <td>1</td>\n",
       "      <td>Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If movies were trying to be more realistic, pe...</td>\n",
       "      <td>7</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Eighteen years ago, on New Year’s Eve, David F...</td>\n",
       "      <td>1</td>\n",
       "      <td>Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>For years now, some of the best, wildest, most...</td>\n",
       "      <td>4</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>For years now, some of the best, wildest, most...</td>\n",
       "      <td>4</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Colorado River is like a giant bank accoun...</td>\n",
       "      <td>7</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>For the last installment of NPR’s holiday reci...</td>\n",
       "      <td>7</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Being overweight can raise your blood pressure...</td>\n",
       "      <td>7</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Who’s the YouTube star of 2016? Adele singing ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Here’s a quick roundup of some of the   you ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ben Johnston doesn’t follow the rules of music...</td>\n",
       "      <td>4</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>David Bowie, Prince and George Michael are all...</td>\n",
       "      <td>4</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>In November, the typically straitlaced Office ...</td>\n",
       "      <td>8</td>\n",
       "      <td>Presidential Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>This is the time of year when everybody is mak...</td>\n",
       "      <td>4</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Terrorist attacks, hurricanes, a divisive U. S...</td>\n",
       "      <td>1</td>\n",
       "      <td>Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>We all experience stress at work, no matter th...</td>\n",
       "      <td>7</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>When John Fahey recorded The New Possibility i...</td>\n",
       "      <td>4</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>This year was one of   hacks, exploding smartp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Article  Topic  \\\n",
       "0   In the Washington of 2016, even when the polic...      8   \n",
       "1     Donald Trump has used Twitter  —   his prefe...      8   \n",
       "2     Donald Trump is unabashedly praising Russian...      8   \n",
       "3   Updated at 2:50 p. m. ET, Russian President Vl...      8   \n",
       "4   From photography, illustration and video, to d...      7   \n",
       "5   I did not want to join yoga class. I hated tho...      5   \n",
       "6   With a   who has publicly supported the debunk...      5   \n",
       "7   I was standing by the airport exit, debating w...      1   \n",
       "8   If movies were trying to be more realistic, pe...      7   \n",
       "9   Eighteen years ago, on New Year’s Eve, David F...      1   \n",
       "10  For years now, some of the best, wildest, most...      4   \n",
       "11  For years now, some of the best, wildest, most...      4   \n",
       "12  The Colorado River is like a giant bank accoun...      7   \n",
       "13  For the last installment of NPR’s holiday reci...      7   \n",
       "14  Being overweight can raise your blood pressure...      7   \n",
       "15  Who’s the YouTube star of 2016? Adele singing ...      4   \n",
       "16  Here’s a quick roundup of some of the   you ma...      1   \n",
       "17  Ben Johnston doesn’t follow the rules of music...      4   \n",
       "18  David Bowie, Prince and George Michael are all...      4   \n",
       "19  In November, the typically straitlaced Office ...      8   \n",
       "20  This is the time of year when everybody is mak...      4   \n",
       "21  Terrorist attacks, hurricanes, a divisive U. S...      1   \n",
       "22  We all experience stress at work, no matter th...      7   \n",
       "23  When John Fahey recorded The New Possibility i...      4   \n",
       "24  This year was one of   hacks, exploding smartp...      4   \n",
       "\n",
       "               Topic Labels  \n",
       "0   Presidential Management  \n",
       "1   Presidential Management  \n",
       "2   Presidential Management  \n",
       "3   Presidential Management  \n",
       "4                 Education  \n",
       "5            Pharmacy/Drugs  \n",
       "6            Pharmacy/Drugs  \n",
       "7                    Family  \n",
       "8                 Education  \n",
       "9                    Family  \n",
       "10                    Music  \n",
       "11                    Music  \n",
       "12                Education  \n",
       "13                Education  \n",
       "14                Education  \n",
       "15                    Music  \n",
       "16                   Family  \n",
       "17                    Music  \n",
       "18                    Music  \n",
       "19  Presidential Management  \n",
       "20                    Music  \n",
       "21                   Family  \n",
       "22                Education  \n",
       "23                    Music  \n",
       "24                    Music  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3402d08",
   "metadata": {},
   "source": [
    "## Using Non-Negatice Matrix Factorization(NMF) Algorithm to perform Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2e78968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b14af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(max_df = 0.95, min_df = 2, stop_words = \"english\")\n",
    "tfidf_data = tfidf_vec.fit_transform(data.Article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d7e76a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84de274f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_data.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431c8337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
