{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538f49a7",
   "metadata": {},
   "source": [
    "# Tokenization Introduction by `Mr. Harshit Dawar!`\n",
    "* It is just the process of just dividing the sentence into words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef73ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "english_model_nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddea1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sentence for the demo!\n",
    "sentence = english_model_nlp(\"This is my first class for NLP in India \\\n",
    "by Mr. Harshit Dawar!, I am super excited for this class.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb72872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "my\n",
      "first\n",
      "class\n",
      "for\n",
      "NLP\n",
      "in\n",
      "India\n",
      "by\n",
      "Mr.\n",
      "Harshit\n",
      "Dawar\n",
      "!\n",
      ",\n",
      "I\n",
      "am\n",
      "super\n",
      "excited\n",
      "for\n",
      "this\n",
      "class\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a31d8",
   "metadata": {},
   "source": [
    "***Using a natural language processing library is important because it knows internally that even \".\" is a separate token. Although we can use split() funciton in python, but only that will not give us the right result, we have to apply multiple other conditions also to capture everything, which consumes a lot of time & efforts.***\n",
    "\n",
    "**A demo is present in the below cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ecd89d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'my', 'first', 'class', 'for', 'NLP', 'in', 'India', 'by', 'Mr.', 'Harshit', 'Dawar!,', 'I', 'am', 'super', 'excited', 'for', 'this', 'class.']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is my first class for NLP in India \\\n",
    "by Mr. Harshit Dawar!, I am super excited for this class.\"\n",
    "\n",
    "print([token for token in sentence.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19273f6c",
   "metadata": {},
   "source": [
    "***As you can see that this splitting doesn't done the work as the above NLP library did***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e601c498",
   "metadata": {},
   "source": [
    "# Congratulations, you have learned about the Tokenization!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
